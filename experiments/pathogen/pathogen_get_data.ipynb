{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathogen Dataset Download and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data code from repository suinleelab **contrastiveVI**: https://github.com/suinleelab/contrastiveVI/blob/main/contrastive_vi/data/datasets/haber_2017.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link to download the data is in the code. The Pathogen data is from Gene Expression Omnibus (GEO) public genomics data repository (https://ftp.ncbi.nlm.nih.gov/geo/series/GSE92nnn/GSE92332/suppl). The particular dataset for this experiment is \"SalmHelm_UMIcounts.txt.gz\" in the repository. The license of the organization can be found here: https://catalog.data.gov/dataset/gene-expression-omnibus-geo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python **anndata** package is found here: https://github.com/scverse/anndata?tab=BSD-3-Clause-1-ov-file\n",
    "\n",
    "The **scanpy** package is found here: https://github.com/scverse/scanpy\n",
    "\n",
    "The **requests** package is found here: https://github.com/psf/requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download, read, and preprocess Haber et al. (2017) expression data.\n",
    "\n",
    "Single-cell expression data from Haber et al. A single-cell survey of the small\n",
    "intestinal epithelium. Nature (2017).\n",
    "\"\"\"\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_binary_file(file_url: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Download binary data file from a URL.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        file_url: URL where the file is hosted.\n",
    "        output_path: Output path for the downloaded file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None.\n",
    "    \"\"\"\n",
    "    request = requests.get(file_url)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(request.content)\n",
    "    print(f\"Downloaded data from {file_url} at {output_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "def download_haber_2017(output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Download Haber et al. 2017 data from the hosting URLs.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        output_path: Output path to store the downloaded and unzipped\n",
    "        directories.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None. File directories are downloaded to output_path.\n",
    "    \"\"\"\n",
    "\n",
    "    url = (\n",
    "        \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE92nnn/GSE92332/suppl/GSE92332\"\n",
    "        \"_SalmHelm_UMIcounts.txt.gz\"\n",
    "    )\n",
    "\n",
    "    output_filename = os.path.join(output_path, url.split(\"/\")[-1])\n",
    "\n",
    "    download_binary_file(url, output_filename)\n",
    "\n",
    "\n",
    "def read_haber_2017(file_directory: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the expression data for Download Haber et al. 2017 the given directory.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        file_directory: Directory containing Haber et al. 2017 data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A data frame containing single-cell gene expression count, with cell\n",
    "        identification barcodes as column names and gene IDs as indices.\n",
    "    \"\"\"\n",
    "\n",
    "    with gzip.open(\n",
    "        os.path.join(file_directory, \"GSE92332_SalmHelm_UMIcounts.txt.gz\"), \"rb\"\n",
    "    ) as f:\n",
    "        df = pd.read_csv(f, sep=\"\\t\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_haber_2017(download_path: str, n_top_genes: int) -> AnnData:\n",
    "    \"\"\"\n",
    "    Preprocess expression data from Haber et al. 2017.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        download_path: Path containing the downloaded Haber et al. 2017 data file.\n",
    "        n_top_genes: Number of most variable genes to retain.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        An AnnData object containing single-cell expression data. The layer\n",
    "        \"count\" contains the count data for the most variable genes. The X\n",
    "        variable contains the total-count-normalized and log-transformed data\n",
    "        for the most variable genes (a copy with all the genes is stored in\n",
    "        .raw).\n",
    "    \"\"\"\n",
    "\n",
    "    df = read_haber_2017(download_path)\n",
    "    df = df.transpose()\n",
    "\n",
    "    cell_groups = []\n",
    "    barcodes = []\n",
    "    conditions = []\n",
    "    cell_types = []\n",
    "\n",
    "    for cell in df.index:\n",
    "        cell_group, barcode, condition, cell_type = cell.split(\"_\")\n",
    "        cell_groups.append(cell_group)\n",
    "        barcodes.append(barcode)\n",
    "        conditions.append(condition)\n",
    "        cell_types.append(cell_type)\n",
    "\n",
    "    \n",
    "    # print(cell_groups)\n",
    "    # print(barcodes)\n",
    "    # print(conditions)\n",
    "    # print(cell_types)\n",
    "\n",
    "    metadata_df = pd.DataFrame(\n",
    "        {\n",
    "            \"cell_group\": cell_groups,\n",
    "            \"barcode\": barcodes,\n",
    "            \"condition\": conditions,\n",
    "            \"cell_type\": cell_types,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    adata = AnnData(X=df.values, obs=metadata_df)\n",
    "    adata = adata[adata.obs[\"condition\"] != \"Hpoly.Day3\"]\n",
    "    adata.layers[\"count\"] = adata.X.copy()\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.raw = adata\n",
    "    sc.pp.highly_variable_genes(\n",
    "        adata, flavor=\"seurat_v3\", n_top_genes=n_top_genes, layer=\"count\", subset=True\n",
    "    )\n",
    "    adata = adata[adata.layers[\"count\"].sum(1) != 0]  # Remove cells with all zeros.\n",
    "    return adata, conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = \"...\"   # local computer data path to downloaad the dataset. \n",
    "\n",
    "download_haber_2017(root_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data, conditions = preprocess_haber_2017(root_data_path, 1000)\n",
    "\n",
    "# print(np.unique(conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to Get Foreground and Background  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240\n",
      "4481\n"
     ]
    }
   ],
   "source": [
    "foreground = data[data.obs[\"condition\"] != \"Control\"]\n",
    "k, p = foreground.shape\n",
    "\n",
    "\n",
    "background = data[data.obs[\"condition\"] == \"Control\"]\n",
    "m, p = background.shape\n",
    "\n",
    "print(m)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground = foreground.to_df()\n",
    "background = background.to_df()\n",
    "\n",
    "\n",
    "foreground.to_csv(\"pathogen_fore.csv\")\n",
    "background.to_csv(\"pathogen_back.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7721\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "n, p = data.shape\n",
    "print(n)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
