{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3584714a",
   "metadata": {},
   "source": [
    "### Perturb_seq Dataset Download and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0a11a",
   "metadata": {},
   "source": [
    "Preprocessing data code from repository suinleelab **contrastiveVI**: https://github.com/suinleelab/contrastiveVI/blob/main/contrastive_vi/data/datasets/norman_2019.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1fa7d1",
   "metadata": {},
   "source": [
    "The link to download the data is in the code. The Perturb_seq data is from Gene Expression Omnibus (GEO) public genomics data repository (https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133344/suppl). The particular dataset for this experiment are \"GSE133344_filtered_matrix.mtx.gz\", \"GSE133344_filtered_genes.tsv.gz\", \"GSE133344_filtered_barcodes.tsv.gz\", and \"GSE133344_filtered_cell_identities.csv.gz\" in the repository. The data is licensed with Open Data Commons Open Database License. The license of the data can be found here: https://catalog.data.gov/dataset/gene-expression-omnibus-geo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf8e5f",
   "metadata": {},
   "source": [
    "The python **anndata** package is found here: https://github.com/scverse/anndata?tab=BSD-3-Clause-1-ov-file\n",
    "\n",
    "The **scanpy** package is found here: https://github.com/scverse/scanpy\n",
    "\n",
    "The **requests** package is found here: https://github.com/psf/requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758f12ac-7dd7-434e-b518-56143b5866af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download, read, and preprocess Norman et al. (2019) expression data.\n",
    "\n",
    "Single-cell expression data from Norman et al. Exploring genetic interaction\n",
    "manifolds constructed from rich single-cell phenotypes. Science (2019).\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "from scipy.io import mmread\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "# Gene program lists obtained by cross-referencing the heatmap here\n",
    "# https://github.com/thomasmaxwellnorman/Perturbseq_GI/blob/master/GI_optimal_umap.ipynb\n",
    "# with Figure 2b in Norman 2019\n",
    "G1_CYCLE = [\n",
    "    \"CDKN1C+CDKN1B\",\n",
    "    \"CDKN1B+ctrl\",\n",
    "    \"CDKN1B+CDKN1A\",\n",
    "    \"CDKN1C+ctrl\",\n",
    "    \"ctrl+CDKN1A\",\n",
    "    \"CDKN1C+CDKN1A\",\n",
    "    \"CDKN1A+ctrl\",\n",
    "]\n",
    "\n",
    "ERYTHROID = [\n",
    "    \"BPGM+SAMD1\",\n",
    "    \"ATL1+ctrl\",\n",
    "    \"UBASH3B+ZBTB25\",\n",
    "    \"PTPN12+PTPN9\",\n",
    "    \"PTPN12+UBASH3A\",\n",
    "    \"CBL+CNN1\",\n",
    "    \"UBASH3B+CNN1\",\n",
    "    \"CBL+UBASH3B\",\n",
    "    \"UBASH3B+PTPN9\",\n",
    "    \"PTPN1+ctrl\",\n",
    "    \"CBL+PTPN9\",\n",
    "    \"CNN1+UBASH3A\",\n",
    "    \"CBL+PTPN12\",\n",
    "    \"PTPN12+ZBTB25\",\n",
    "    \"UBASH3B+PTPN12\",\n",
    "    \"SAMD1+PTPN12\",\n",
    "    \"SAMD1+UBASH3B\",\n",
    "    \"UBASH3B+UBASH3A\",\n",
    "]\n",
    "\n",
    "PIONEER_FACTORS = [\n",
    "    \"ZBTB10+SNAI1\",\n",
    "    \"FOXL2+MEIS1\",\n",
    "    \"POU3F2+CBFA2T3\",\n",
    "    \"DUSP9+SNAI1\",\n",
    "    \"FOXA3+FOXA1\",\n",
    "    \"FOXA3+ctrl\",\n",
    "    \"LYL1+IER5L\",\n",
    "    \"FOXA1+FOXF1\",\n",
    "    \"FOXF1+HOXB9\",\n",
    "    \"FOXA1+HOXB9\",\n",
    "    \"FOXA3+HOXB9\",\n",
    "    \"FOXA3+FOXA1\",\n",
    "    \"FOXA3+FOXL2\",\n",
    "    \"POU3F2+FOXL2\",\n",
    "    \"FOXF1+FOXL2\",\n",
    "    \"FOXA1+FOXL2\",\n",
    "    \"HOXA13+ctrl\",\n",
    "    \"ctrl+HOXC13\",\n",
    "    \"HOXC13+ctrl\",\n",
    "    \"MIDN+ctrl\",\n",
    "    \"TP73+ctrl\",\n",
    "]\n",
    "\n",
    "GRANULOCYTE_APOPTOSIS = [\n",
    "    \"SPI1+ctrl\",\n",
    "    \"ctrl+SPI1\",\n",
    "    \"ctrl+CEBPB\",\n",
    "    \"CEBPB+ctrl\",\n",
    "    \"JUN+CEBPA\",\n",
    "    \"CEBPB+CEBPA\",\n",
    "    \"FOSB+CEBPE\",\n",
    "    \"ZC3HAV1+CEBPA\",\n",
    "    \"KLF1+CEBPA\",\n",
    "    \"ctrl+CEBPA\",\n",
    "    \"CEBPA+ctrl\",\n",
    "    \"CEBPE+CEBPA\",\n",
    "    \"CEBPE+SPI1\",\n",
    "    \"CEBPE+ctrl\",\n",
    "    \"ctrl+CEBPE\",\n",
    "    \"CEBPE+RUNX1T1\",\n",
    "    \"CEBPE+CEBPB\",\n",
    "    \"FOSB+CEBPB\",\n",
    "    \"ETS2+CEBPE\",\n",
    "]\n",
    "\n",
    "MEGAKARYOCYTE = [\n",
    "    \"ctrl+ETS2\",\n",
    "    \"MAPK1+ctrl\",\n",
    "    \"ctrl+MAPK1\",\n",
    "    \"ETS2+MAPK1\",\n",
    "    \"CEBPB+MAPK1\",\n",
    "    \"MAPK1+TGFBR2\",\n",
    "]\n",
    "\n",
    "PRO_GROWTH = [\n",
    "    \"CEBPE+KLF1\",\n",
    "    \"KLF1+MAP2K6\",\n",
    "    \"AHR+KLF1\",\n",
    "    \"ctrl+KLF1\",\n",
    "    \"KLF1+ctrl\",\n",
    "    \"KLF1+BAK1\",\n",
    "    \"KLF1+TGFBR2\",\n",
    "]\n",
    "\n",
    "\n",
    "def download_binary_file(file_url: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Download binary data file from a URL.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        file_url: URL where the file is hosted.\n",
    "        output_path: Output path for the downloaded file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None.\n",
    "    \"\"\"\n",
    "    request = requests.get(file_url)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(request.content)\n",
    "    print(f\"Downloaded data from {file_url} at {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_norman_2019(output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Download Norman et al. 2019 data and metadata files from the hosting URLs.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        output_path: Output path to store the downloaded and unzipped\n",
    "        directories.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None. File directories are downloaded to output_path.\n",
    "    \"\"\"\n",
    "\n",
    "    file_urls = (\n",
    "        \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133344/suppl\"\n",
    "        \"/GSE133344_filtered_matrix.mtx.gz\",\n",
    "        \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133344/suppl\"\n",
    "        \"/GSE133344_filtered_genes.tsv.gz\",\n",
    "        \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133344/suppl\"\n",
    "        \"/GSE133344_filtered_barcodes.tsv.gz\",\n",
    "        \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133344/suppl\"\n",
    "        \"/GSE133344_filtered_cell_identities.csv.gz\",\n",
    "    )\n",
    "\n",
    "    for url in file_urls:\n",
    "        output_filename = os.path.join(output_path, url.split(\"/\")[-1])\n",
    "        download_binary_file(url, output_filename)\n",
    "\n",
    "\n",
    "def read_norman_2019(file_directory: str) -> coo_matrix:\n",
    "    \"\"\"\n",
    "    Read the expression data for Norman et al. 2019 in the given directory.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        file_directory: Directory containing Norman et al. 2019 data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A sparse matrix containing single-cell gene expression count, with rows\n",
    "        representing genes and columns representing cells.\n",
    "    \"\"\"\n",
    "\n",
    "    with gzip.open(\n",
    "        os.path.join(file_directory, \"GSE133344_filtered_matrix.mtx.gz\"), \"rb\"\n",
    "    ) as f:\n",
    "        matrix = mmread(f)\n",
    "        \n",
    "    print(\"read\")\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def preprocess_norman_2019(download_path: str, n_top_genes: int) -> AnnData:\n",
    "    \"\"\"\n",
    "    Preprocess expression data from Norman et al. 2019.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        download_path: Path containing the downloaded Norman et al. 2019 data file.\n",
    "        n_top_genes: Number of most variable genes to retain.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        An AnnData object containing single-cell expression data. The layer\n",
    "        \"count\" contains the count data for the most variable genes. The .X\n",
    "        variable contains the normalized and log-transformed data for the most variable\n",
    "        genes. A copy of data with all genes is stored in .raw.\n",
    "    \"\"\"\n",
    "    matrix = read_norman_2019(download_path)\n",
    "\n",
    "    # List of cell barcodes. The barcodes in this list are stored in the same order\n",
    "    # as cells are in the count matrix.\n",
    "    cell_barcodes = pd.read_csv(\n",
    "        os.path.join(download_path, \"GSE133344_filtered_barcodes.tsv.gz\"),\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"cell_barcode\"],\n",
    "    )\n",
    "    \n",
    "\n",
    "    # IDs/names of the gene features.\n",
    "    gene_list = pd.read_csv(\n",
    "        os.path.join(download_path, \"GSE133344_filtered_genes.tsv.gz\"),\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"gene_id\", \"gene_name\"],\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Dataframe where each row corresponds to a cell, and each column corresponds\n",
    "    # to a gene feature.\n",
    "    matrix = pd.DataFrame(\n",
    "        matrix.transpose().todense(),\n",
    "        columns=gene_list[\"gene_id\"],\n",
    "        index=cell_barcodes[\"cell_barcode\"],\n",
    "        dtype=\"int32\",\n",
    "    )\n",
    "\n",
    "    # Dataframe mapping cell barcodes to metadata about that cell (e.g. which CRISPR\n",
    "    # guides were applied to that cell). Unfortunately, this list has a different\n",
    "    # ordering from the count matrix, so we have to be careful combining the metadata\n",
    "    # and count data.\n",
    "    cell_identities = pd.read_csv(\n",
    "        os.path.join(download_path, \"GSE133344_filtered_cell_identities.csv.gz\")\n",
    "    ).set_index(\"cell_barcode\")\n",
    "    \n",
    "\n",
    "    # This merge call reorders our metadata dataframe to match the ordering in the\n",
    "    # count matrix. Some cells in `cell_barcodes` do not have metadata associated with\n",
    "    # them, and their metadata values will be filled in as NaN.\n",
    "    aligned_metadata = pd.merge(\n",
    "        cell_barcodes,\n",
    "        cell_identities,\n",
    "        left_on=\"cell_barcode\",\n",
    "        right_index=True,\n",
    "        how=\"left\",\n",
    "    ).set_index(\"cell_barcode\")\n",
    "\n",
    "    \n",
    "    adata = AnnData(matrix)\n",
    "    adata.obs = aligned_metadata\n",
    "\n",
    "    # Filter out any cells that don't have metadata values.\n",
    "    rows_without_nans = [\n",
    "        index for index, row in adata.obs.iterrows() if not row.isnull().any()\n",
    "    ]\n",
    "    adata = adata[rows_without_nans, :]\n",
    "\n",
    "    # Remove these as suggested by the authors. See lines referring to\n",
    "    # NegCtrl1_NegCtrl0 in GI_generate_populations.ipynb in the Norman 2019 paper's\n",
    "    # Github repo https://github.com/thomasmaxwellnorman/Perturbseq_GI/\n",
    "    adata = adata[adata.obs[\"guide_identity\"] != \"NegCtrl1_NegCtrl0__NegCtrl1_NegCtrl0\"]\n",
    "\n",
    "    # We create a new metadata column with cleaner representations of CRISPR guide\n",
    "    # identities. The original format is <Guide1>_<Guide2>__<Guide1>_<Guide2>_<number>\n",
    "    adata.obs[\"guide_merged\"] = adata.obs[\"guide_identity\"]\n",
    "\n",
    "    control_regex = re.compile(r\"NegCtrl(.*)_NegCtrl(.*)+NegCtrl(.*)_NegCtrl(.*)\")\n",
    "    for i in adata.obs[\"guide_merged\"].unique():\n",
    "        if control_regex.match(i):\n",
    "            # For any cells that only had control guides, we don't care about the\n",
    "            # specific IDs of the guides. Here we relabel them just as \"ctrl\".\n",
    "            adata.obs[\"guide_merged\"].replace(i, \"ctrl\", inplace=True)\n",
    "        else:\n",
    "            # Otherwise, we reformat the guide label to be <Guide1>+<Guide2>. If Guide1\n",
    "            # or Guide2 was a control, we replace it with \"ctrl\".\n",
    "            split = i.split(\"__\")[0]\n",
    "            split = split.split(\"_\")\n",
    "            for j, string in enumerate(split):\n",
    "                if \"NegCtrl\" in split[j]:\n",
    "                    split[j] = \"ctrl\"\n",
    "            adata.obs[\"guide_merged\"].replace(i, f\"{split[0]}+{split[1]}\", inplace=True)\n",
    "\n",
    "    guides_to_programs = {}\n",
    "    guides_to_programs.update(dict.fromkeys(G1_CYCLE, \"G1 cell cycle arrest\"))\n",
    "    guides_to_programs.update(dict.fromkeys(ERYTHROID, \"Erythroid\"))\n",
    "    guides_to_programs.update(dict.fromkeys(PIONEER_FACTORS, \"Pioneer factors\"))\n",
    "    guides_to_programs.update(\n",
    "        dict.fromkeys(GRANULOCYTE_APOPTOSIS, \"Granulocyte/apoptosis\")\n",
    "    )\n",
    "    guides_to_programs.update(dict.fromkeys(PRO_GROWTH, \"Pro-growth\"))\n",
    "    guides_to_programs.update(dict.fromkeys(MEGAKARYOCYTE, \"Megakaryocyte\"))\n",
    "    guides_to_programs.update(dict.fromkeys([\"ctrl\"], \"Ctrl\"))\n",
    "\n",
    "    # We only keep cells whose guides were either controls or are labeled with a\n",
    "    # specific gene program\n",
    "    adata = adata[adata.obs[\"guide_merged\"].isin(guides_to_programs.keys())]\n",
    "    adata.obs[\"gene_program\"] = [\n",
    "        guides_to_programs[x] for x in adata.obs[\"guide_merged\"]\n",
    "    ]\n",
    "\n",
    "    adata.obs[\"good_coverage\"] = adata.obs[\"good_coverage\"].astype(bool)\n",
    "\n",
    "    adata.layers[\"count\"] = adata.X.copy()\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.raw = adata\n",
    "    sc.pp.highly_variable_genes(\n",
    "        adata, flavor=\"seurat_v3\", n_top_genes=n_top_genes, layer=\"count\", subset=True\n",
    "    )\n",
    "    adata = adata[adata.layers[\"count\"].sum(1) != 0]  # Remove cells with all zeros.\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe80ae",
   "metadata": {},
   "source": [
    "### Process to Get Foreground and Background  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a07a86f-3488-4ecc-84ca-a454dbd7ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "data = preprocess_norman_2019(\"\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d330731d-a870-446a-bb7c-48d34fb8011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = data[data.obs['guide_merged'] == 'ctrl']\n",
    "control = control.to_df()\n",
    "# print(control.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "413c6007-eeae-4c60-8f2e-52dfb4cd60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRISPR_perturbation = data[data.obs['guide_merged'] != 'ctrl']\n",
    "CRISPR_perturbation = CRISPR_perturbation.to_df()\n",
    "# print(CRISPR_perturbation.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c44461-7033-4581-a01b-425135e2c5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1:  24913\n",
      "n2:  8907\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "foreground = CRISPR_perturbation\n",
    "background = control\n",
    "\n",
    "foreground.to_csv(\"CRISPR_perturbation.csv\")\n",
    "background.to_csv(\"control_perturb_seq.csv\")\n",
    "\n",
    "n1, p = foreground.shape\n",
    "n2, k = background.shape\n",
    "\n",
    "# get the dimension for the fore and back matrix \n",
    "print(\"n1: \", n1)\n",
    "print(\"n2: \", n2) \n",
    "print(p)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42b801",
   "metadata": {},
   "source": [
    "### Run Contrastive Dimension Estimation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7883d79a-5468-41e7-8ad5-dd0a35a19a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skdim\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "def id_estimators(df, k):\n",
    "    # Maximum Likelihood algorithm\n",
    "    MLE = skdim.id.MLE(K=k).fit(df).dimension_\n",
    "    # Method Of Moments algorithm\n",
    "    MOM = skdim.id.MOM().fit(df).dimension_\n",
    "    L = {\n",
    "        'MLE': MLE,\n",
    "        'MOM': MOM,\n",
    "    }\n",
    "    return L\n",
    "\n",
    "\n",
    "def est_V1_V2(X1, X2, d1, d2):\n",
    "    OUT = {}\n",
    "    p = X1.shape[1]\n",
    "    Cx1 = np.cov(X1, rowvar=False)\n",
    "    Cx2 = np.cov(X2, rowvar=False)\n",
    "    # eigenvalues python package in increasing order\n",
    "    val1, vectors1 = eigh(Cx1)\n",
    "    idx = np.argsort(val1)\n",
    "    descending_idx = idx[::-1]\n",
    "    vectors1 = vectors1[:, descending_idx]\n",
    "    V1 = vectors1[:, 0:d1]\n",
    "    val2, vectors2 = eigh(Cx2)\n",
    "    idx_ = np.argsort(val2)\n",
    "    descending_idx_ = idx_[::-1]\n",
    "    vectors2 = vectors2[:, descending_idx_]\n",
    "    V2 = vectors2[:, 0:d2]\n",
    "    OUT['V1'] = V1\n",
    "    OUT['V2'] = V2\n",
    "    return OUT\n",
    "\n",
    "\n",
    "def sigma1_test_stat(X1, X2, d1, d2):\n",
    "    OUT = est_V1_V2(X1, X2, d1, d2)\n",
    "    U = OUT['V1']\n",
    "    V = OUT['V2']\n",
    "    M = np.matmul(U.T, V)\n",
    "    _, cosines, _ = np.linalg.svd(M)\n",
    "    cosines = np.minimum(1, np.maximum(-1, cosines))\n",
    "    return cosines[::-1][0]     # first elt of reversed cosines list\n",
    "\n",
    "\n",
    "def sing_vals(U, V):\n",
    "    M = np.matmul(U.T, V)\n",
    "    _, cosines, _ = np.linalg.svd(M)\n",
    "    cosines = np.minimum(1, np.maximum(-1, cosines))\n",
    "    return cosines\n",
    "\n",
    "\n",
    "def boot_test(X1, X2, d1, d2, B):\n",
    "    X1 = scale(X1, with_mean=True, with_std=False)\n",
    "    X2 = scale(X2, with_mean=True, with_std=False)\n",
    "    test_stat = sigma1_test_stat(X1, X2, d1, d2)\n",
    "    n1 = len(X1)\n",
    "    n2 = len(X2)\n",
    "    boot_stats = []\n",
    "    for j in range(1, B+1):\n",
    "        print(j)\n",
    "        idx1 = np.random.choice(range(n1), size=n1, replace=True)\n",
    "        X1t = X1[idx1, :]\n",
    "        combined = np.vstack((X1, X2))\n",
    "        idx2 = np.random.choice(range(n1+n2), size=n2, replace=True)\n",
    "        X2t = combined[idx2, :]\n",
    "        boot_stats.append(sigma1_test_stat(X1t, X2t, d1, d2))\n",
    "    p_value = np.mean(boot_stats < test_stat)\n",
    "    return {'test_stat': test_stat, 'p_value': p_value}\n",
    "\n",
    "\n",
    "def CD(X1, X2, d1, d2, epsilon=0.1, B=1000):\n",
    "    p = X1.shape[1]\n",
    "    OUT = est_V1_V2(X1, X2, d1, d2)\n",
    "    singular_vals = sing_vals(OUT['V1'], OUT['V2'])\n",
    "    singular_vals = singular_vals[::-1]\n",
    "    L = {}\n",
    "    L['CD'] = sum(singular_vals < 1 - epsilon) + max(d1 - d2, 0)\n",
    "    test = boot_test(X1, X2, d1, d2, B)\n",
    "    L['test_stat'] = test['test_stat']\n",
    "    L['p_value'] = test['p_value']\n",
    "    L['singular_vals'] = singular_vals\n",
    "    L['d1'] = d1\n",
    "    L['d2'] = d2\n",
    "    return L\n",
    "\n",
    "\n",
    "def CDE(fg, bg):\n",
    "    L1 = id_estimators(fg, 10)\n",
    "    d1 = round(L1[\"MOM\"])\n",
    "    L2 = id_estimators(bg, 10)\n",
    "    d2 = round(L2[\"MOM\"])\n",
    "    return CD(fg, bg, d1, d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea4fc6e-d5c4-40ca-8988-fb3909d10b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fore = pd.read_csv(\"CRISPR_perturbation.csv\")\n",
    "fore = fore.drop(fore.columns[0], axis=1)\n",
    "back = pd.read_csv(\"control_perturb_seq.csv\")\n",
    "back = back.drop(back.columns[0], axis=1)\n",
    "\n",
    "np.random.seed(42)\n",
    "CDE(fore, back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "elapsed = end - start \n",
    "print(f'Time taken: {elapsed: .6f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
